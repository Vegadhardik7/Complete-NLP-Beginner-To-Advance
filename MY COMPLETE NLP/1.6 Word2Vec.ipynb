{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Preprocessing the data\n",
    "\n",
    "text = re.sub(r'\\[[0-9]*\\]', ' ', paragraph)\n",
    "text = re.sub(r'\\s+',' ', text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d', ' ', text)\n",
    "text = re.sub(r'\\s+', ' ',text)\n",
    "\n",
    "\n",
    "# Preparaing the dataset (Convert para into sentence)\n",
    "\n",
    "sen = nltk.sent_tokenize(text)\n",
    "\n",
    "sen = [nltk.word_tokenize(sen) for sen in sen]\n",
    "\n",
    "for i in range(len(sen)):\n",
    "    sen[i] = [word for word in sen[i] if word not in stopwords.words('english')]\n",
    "    \n",
    "# Training the Word2Vec model\n",
    "\n",
    "model = Word2Vec(sen, min_count=1)\n",
    "\n",
    "words = model.wv.vocab\n",
    "\n",
    "\n",
    "# Finding Word Vectors\n",
    "\n",
    "vector = model.wv['war']\n",
    "\n",
    "# Most similar words\n",
    "\n",
    "similar = model.wv.most_similar('india')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('father', 0.24221770465373993), ('among', 0.23780058324337006), ('free', 0.23668214678764343), ('brahm', 0.20129162073135376), ('worked', 0.18344007432460785), ('greeks', 0.15403857827186584), ('four', 0.14615459740161896), ('lucky', 0.1424834132194519), ('build', 0.1403198540210724), ('sarabhai', 0.12427812814712524)]\n"
     ]
    }
   ],
   "source": [
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.93170963e-03 -1.61415676e-03 -2.32748222e-03 -3.63919744e-03\n",
      " -4.04350320e-03 -3.60003952e-03  2.38173199e-03  6.65343308e-04\n",
      "  4.60194563e-03  1.11809044e-04 -1.81472150e-03  6.64378924e-04\n",
      "  1.71781855e-03 -1.20819558e-03 -3.10085993e-03 -2.87564914e-03\n",
      " -1.47595955e-03 -4.14578570e-03 -1.93365617e-03 -2.68154428e-03\n",
      "  3.64642031e-03 -3.31796519e-03  5.86203008e-04 -3.86140589e-03\n",
      " -4.40311292e-03 -3.97214200e-03  1.45881076e-03 -3.22964205e-03\n",
      " -1.88420317e-03 -1.29216898e-03  3.54223140e-03 -3.47980508e-03\n",
      "  3.67263128e-04  6.30529439e-06 -4.21050983e-03  2.09284038e-03\n",
      " -3.40269902e-03 -3.61600053e-03 -2.69361446e-03  2.31598606e-04\n",
      "  1.50835689e-03  3.47825873e-04 -4.70693596e-03 -2.59292079e-03\n",
      "  2.17764522e-03 -3.88853741e-03 -1.94822066e-03 -1.89249252e-03\n",
      "  2.07238714e-03  1.16710050e-03  2.31690682e-03  3.39554995e-03\n",
      "  3.01597174e-03 -4.34144167e-03  4.94391052e-03 -3.71656730e-03\n",
      "  1.48213282e-03  1.32709986e-03 -4.11647809e-04 -1.97983254e-03\n",
      "  1.75875297e-03  3.61712347e-03 -2.38722842e-03  2.15829769e-03\n",
      "  1.72585284e-03  2.88457493e-03 -7.77416921e-04 -4.48374456e-04\n",
      " -2.64510512e-03 -4.73910058e-03  2.01211520e-03 -3.64974840e-03\n",
      " -1.16429024e-03  6.20352293e-05 -2.74570356e-03 -8.00612499e-04\n",
      "  1.05480081e-03 -2.99339253e-03 -4.19373251e-03 -7.70941435e-04\n",
      "  4.78475587e-03  3.56933975e-04 -4.21973784e-03 -3.22006340e-03\n",
      " -4.57671704e-03 -9.86252679e-04  2.42196396e-03 -2.51125148e-03\n",
      " -1.87466573e-03  1.08431431e-03 -2.36673513e-03  3.18115228e-03\n",
      "  4.85191355e-03 -1.45393459e-03 -1.02538303e-04  3.31021752e-03\n",
      " -2.94699520e-03 -1.02047413e-03 -2.70852330e-03 -1.49605598e-03]\n"
     ]
    }
   ],
   "source": [
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
