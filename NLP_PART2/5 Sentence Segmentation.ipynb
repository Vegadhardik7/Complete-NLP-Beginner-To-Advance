{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# From Spacy Basics:\n",
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Doc.sents` is a generator\n",
    "It is important to note that `doc.sents` is a *generator*. That is, a Doc is not segmented until `doc.sents` is called. This means that, where you could print the second Doc token with `print(doc[1])`, you can't call the \"second Doc sentence\" with `print(doc.sents[1])`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab tokens from the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Can't grab sentences from the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c1472b4bcc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "doc.sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access sents we can put doc into the list and than call the sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(doc.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing right things; leadership is doing the right things.\" -Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Management is doing right things; leadership is doing the right things.\" -Peter Drucker'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing right things; leadership is doing the right things.\"\n",
      "\n",
      "\n",
      "-Peter Drucker\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new rule to the pipe line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***There are 2 ways:***\n",
    "    \n",
    "1.) `Add a segmentation rule`: Basically adding a new thing to segment on.\n",
    "\n",
    "2.) `Change segmentation rule`: Change the rule entierly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Add a Segmentation Rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_boundries(doc):\n",
    "    '''Every token in the doc retains its index position'''\n",
    "    for token in doc:\n",
    "        print(token.i,\"------------>\",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------------> \"\n",
      "1 ------------> Management\n",
      "2 ------------> is\n",
      "3 ------------> doing\n",
      "4 ------------> right\n",
      "5 ------------> things\n",
      "6 ------------> ;\n",
      "7 ------------> leadership\n",
      "8 ------------> is\n",
      "9 ------------> doing\n",
      "10 ------------> the\n",
      "11 ------------> right\n",
      "12 ------------> things\n",
      "13 ------------> .\n",
      "14 ------------> \"\n",
      "15 ------------> -Peter\n",
      "16 ------------> Drucker\n"
     ]
    }
   ],
   "source": [
    "set_custom_boundries(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the index positions of the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------------> \"\n",
      "1 ------------> Management\n",
      "2 ------------> is\n",
      "3 ------------> doing\n",
      "4 ------------> right\n",
      "5 ------------> things\n",
      "6 ------------> ;\n",
      "7 ------------> leadership\n",
      "8 ------------> is\n",
      "9 ------------> doing\n",
      "10 ------------> the\n",
      "11 ------------> right\n",
      "12 ------------> things\n",
      "13 ------------> .\n",
      "14 ------------> \"\n",
      "15 ------------> -Peter\n"
     ]
    }
   ],
   "source": [
    "def set_custom_boundries(doc):\n",
    "    '''Every token in the doc retains its index position'''\n",
    "    for token in doc[:-1]:\n",
    "        print(token.i,\"------------>\",token)\n",
    "        \n",
    "set_custom_boundries(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This goes from 0 till second last element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundries', 'parser', 'ner']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_custom_boundries(doc):\n",
    "    '''Every token in the doc retains its index position'''\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundries, before='parser')\n",
    "        \n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'\"Management is doing right things; leadership is doing the right things.\" -Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing right things;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the segmentation rule of starting next sent from new line if it encounters \";\" is applied directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "___________________________________________________________________________________________________________________________\n",
    "\n",
    "***What happens if we want to change the rules completely?***\n",
    "\n",
    "So in some cases we want to replace spaces defalut sensitizer with our own set of rules.\n",
    "\n",
    "## Change segmentation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset to the original default behaviour\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another. \n",
      "\n",
      "This is a \n",
      "Thirds sentence.\n"
     ]
    }
   ],
   "source": [
    "my_string = u\"This is a sentence. This is another. \\n\\nThis is a \\nThirds sentence.\"\n",
    "\n",
    "print(my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a text dataset for poetry line breaks like this are more important than fullstop(.) and you may want to define line break themselves as the actual end of a sentence instad of what is classicaly known as a end of the sentence i.e <b>' . '</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another. \n",
      "\n",
      "\n",
      "This is a \n",
      "Thirds sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(my_string)\n",
    "\n",
    "\n",
    "for sen in doc.sents:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above one is default,\n",
    "\n",
    "but we actually want <b>\\n</b> as a line break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    seen_new_line = False\n",
    "    \n",
    "    \n",
    "    '''For every word / token in that doc if we already seen new line than we are gonna yield \n",
    "        from start upto that current tokens index as a start or reset the current index pos as\n",
    "        start pos and we'll set seen new line = False\n",
    "    '''\n",
    "    for word in doc:\n",
    "        if seen_new_line:\n",
    "            yield doc[start: word.i]\n",
    "            start = word.i\n",
    "            seen_new_line = False   # reset seen_new_line\n",
    "            \n",
    "        elif word.text.startswith('\\n'):\n",
    "            seen_new_line = True\n",
    "            \n",
    "    yield doc[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n",
    "\n",
    "nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another. \n",
      "\n",
      "\n",
      "This is a \n",
      "\n",
      "Thirds sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(my_string)\n",
    "\n",
    "for sen in doc.sents:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylst = [2,'apple']\n",
    "\n",
    "mylst[1] = 'orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 'orange']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylstlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-828ef36df39c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mabc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "def abc(n=1):\n",
    "    if n>3:\n",
    "        return\n",
    "    print(n)\n",
    "    \n",
    "abc(n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "abc(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
